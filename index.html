<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />

<title>Kai-Fu Yang</title>

</head>
<body>

<!-- Project
<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#services">Services</a> 
<a href="#awards">Awards</a>  
</div>
 -->
 
<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
<!--
<div id="toptitle">
<h1>Kai-Fu Yang</h1>
</div>
 -->

<table class="imgtable"><tr><td>
<a href="./"><img src="./pics/photo.png" alt="" height="220px" /></a>&nbsp;</td>
<td align="left"><p><font size="5">Kai-Fu Yang (杨开富)</font> <br />
Associate Research Professor (副研究员) <br />
Computational Vision, Bio-inspired Computer Vision, Medical Image Analysis <br />
视觉认知计算、计算机视觉、医学图像分析<br />
<br />
<a href="https://www.neuro.uestc.edu.cn/vccl/home.html">Center for Visual Cognition and Brain-Inspired Computation</a><br />
University of Electronic Science and Technology of China (UESTC)<br />
No.4, Section 2, North Jianshe Road, Chengdu 610054, China. <br />
<br />
Email:yangkf [AT] uestc.edu.cn <br />
[<a class="p" href="https://scholar.google.com/citations?user=i0VkF0EAAAAJ&hl=en" target="_blank">Google Scholar</a>]</p>
</td></tr></table>

<h2>About Me</h2>
<p>I am currently an associate research professor with the MOE Key Lab for Neuroinformation, School of Life Science and Technology, 
University of Electronic Science and Technology of China (UESTC), China. I received my Ph.D. degree in Biomedical Engineering from UESTC, in 2016, 
under the supervision of Prof. Yong-Jie Li. I was a visiting scholar from August 2019 to August 2020 in Computer Vision Lab, 
Department of Information Technology and Electrical Engineering, ETH Zurich, Switzerland.</p>

<h2>Research Interests</h2>
I conduct interdisciplinary research at the intersection of visual cognition and computer vision.  
My research aims to explore the underlying computational theory of vision and develop bio-inspired methods for computer vision applications. Through a combination of computational modeling and behavioral experiments (e.g., eye-tracking), we try to explore the computational basis of many aspects of vision, such as visual perception, visual attention, and object understanding.<br />
	
<br />
Recent research topics:
<li> Visual Object Understanding</li>
<li> Adaptive Visual Perception</li>
<li> Ophthalmic image analysis</li>

<!--<h2>News</h2>-->
<!--<ul>-->
<!--<li> XXXX.</li>-->
<!--</ul>-->

<!-- Project -->
<a id="projects" class="anchor"></a>
<h2>Projects and Publications</h2>

<table class="imgtable">
	
	
<!--Adaptation-->
<tr>
<td><img class="proj_thumb" src="./pics/VisEnh.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Visual Adaptation and Image Enhancement  </p>
<font size="2.5">
<li><b>KF Yang</b>, C Cheng, SX Zhao, HM Yan, XS Zhang, YJ Li. Learning to Adapt to Light. <b>IJCV</b>, 2023. [<a class="p" href="https://github.com/kaifuyang/LA-Net" target="_blank">Codes</a>]</li>
<li><b>KF Yang</b>, XS Zhang, YJ Li. A Biological Vision Inspired Framework for Image Enhancement in Poor Visibility Conditions. <b>IEEE TIP</b>, 2020. [<a class="p" href="https://github.com/kaifuyang/Visual-Adaptation" target="_blank">Codes</a>]</li>
<li><b>KF Yang</b>, H Li, HL Kuang, CY Li, YJ Li. An Adaptive Method for Image Dynamic Range Adjustment. <b>IEEE TCSVT</b>, 2019. [<a class="p" href="https://github.com/kaifuyang/Visual-Adaptation" target="_blank">Codes</a>]</li>
</font>
</p> </td>
</tr>

		
<!-- Grey Pixel-->
<tr>
<td><img class="proj_thumb" src="./pics/CC.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Gray Pixel and Color Constancy</p>
<font size="2.5">
<li><b>KF Yang</b>, SB Gao, YJ Li. Efficient Illuminant Estimation for Color Constancy Using Grey Pixels. <b>CVPR</b>, 2015. [<a class="p" href="https://github.com/kaifuyang/Gray-Pixel" target="_blank">Codes</a>]</li>
<li>SB Gao, <b>KF Yang</b>, CY Li, YJ Li. Color Constancy Using Double-Opponency. <b>IEEE TPAMI</b>, 2015.</li>
<li>SB Gao, <b>KF Yang</b>, CY Li, YJ Li. A Color Constancy Model with Double-Opponency Mechanisms. <b>ICCV</b>, 2013.</li>
</font>
</p> </td>
</tr>


<!--Attention-->
<tr>
<td><img class="proj_thumb" src="./pics/VisAtt.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Guided Attention and Saliency Detection</p>
<font size="2.5">
<li>P Peng, <b>KF Yang</b>, SQ Liang, YJ Li. Contour-guided Saliency Detection with Long-range Interactions. <b>Neurocomputing</b>, 2022. [<a class="p" href="https://github.com/PengPanda/LRSP" target="_blank">Codes</a>]</li>
<li>P Peng, <b>KF Yang</b>, FY Luo, YJ Li. Saliency Detection Inspired by Topological Perception Theory. <b>IJCV</b>, 2021. [<a class="p" href="https://github.com/PengPanda/TopologicalSaliency" target="_blank">Codes</a>]</li>
<li><b>KF Yang</b>, H Li, CY Li, YJ Li. A Unified Framework for Salient Structure Detection by Contour-Guided Visual Search. <b>IEEE TIP</b>, 2016. [<a class="p" href="https://github.com/kaifuyang/Guided-Attention" target="_blank">Codes</a>]</li>
</font>
</p> </td>
</tr>
	
	
<!-- CRF Model-->
<tr>
<td><img class="proj_thumb" src="./pics/CRF.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Receptive Field Models and Contour Detection </p>
<font size="2.5">
<li><b>KF Yang</b>, SB Gao, CF Guo, CY Li, YJ Li. Boundary Detection Using Double-Opponency and Spatial Sparseness Constraint. <b>IEEE TIP</b>, 2015. [<a class="p" href="https://github.com/kaifuyang/Receptive-Field-Models" target="_blank">Codes</a>]</li>
<li><b>KF Yang</b>, CY Li, YJ Li. Multifeature-based Surround Inhibition Improves Contour Detection in Natural Images. <b>IEEE TIP</b>, 2014. [<a class="p" href="https://github.com/kaifuyang/Receptive-Field-Models" target="_blank">Codes</a>]</li>
<li><b>KF Yang</b>, SB Gao, CY Li, YJ Li. Efficient Color Boundary Detection with Color-opponent Mechanisms. <b>CVPR</b>, 2013. [<a class="p" href="https://github.com/kaifuyang/Receptive-Field-Models" target="_blank">Codes</a>]</li>
</font>
</p> </td>
</tr>
	
	
<!--Ophthalmic--> 
<tr>
<td><img class="proj_thumb" src="./pics/OphImg.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Ophthalmic Image Analysis</p>
<font size="2.5">
<li>YB Tan, <b>KF Yang</b>, SX Zhao, YJ Li. Retinal Vessel Segmentation with Skeletal Prior and Contrastive Loss. <b>IEEE TMI</b>, 2022. [<a class="p" href="https://github.com/tyb311/SkelCon" target="_blank">Codes</a>]</li>
<li>J Wang, YJ Li, <b>KF Yang</b>. Retinal fundus Image Enhancement with Image Decomposition and Visual Adaptation. <b>Comput. Biol. Med.</b>, 2021.</li>
</font>
</p> </td>
</tr>

</table> 


<div id="footer">
<div id="footer-text">

</div>
</div>
</body>
</html>
